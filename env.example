# Environment Configuration Example
# Copy this file to .env and configure for your environment

# Environment
ENVIRONMENT=development

# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_USERNAME=postgres
DB_PASSWORD=your_password_here
DB_DATABASE=real_estate_scraper

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=true
SECRET_KEY=your-secret-key-change-this-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
RATE_LIMIT_PER_MINUTE=100

# Scraping Configuration
REQUESTS_PER_MINUTE=30
DELAY_BETWEEN_REQUESTS=2.0
USE_PROXY=false
PROXY_LIST=
ROTATE_USER_AGENTS=true
HEADLESS_BROWSER=true
BROWSER_TIMEOUT=30
RANDOM_DELAYS=true
MIN_DELAY=1.0
MAX_DELAY=5.0

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

# Monitoring Configuration
SENTRY_DSN=

# Email Alerts (Optional)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your_email@gmail.com
SMTP_PASSWORD=your_app_password
FROM_EMAIL=your_email@gmail.com
TO_EMAILS=admin@yourdomain.com,alerts@yourdomain.com

# Chrome/Selenium Configuration
CHROME_BIN=/usr/bin/google-chrome
CHROME_PATH=/usr/bin/google-chrome

# Data Processing Configuration
ETL_BATCH_SIZE=100
MAX_PROCESSING_ERRORS=10
DEDUPLICATION_THRESHOLD=0.85

# Scheduling Configuration
ENABLE_SCHEDULED_SCRAPING=true
DAILY_SCRAPING_LOCATIONS=San Francisco CA,New York NY,Los Angeles CA
MAX_RESULTS_PER_SCRAPE=1000

# Security Configuration
ALLOWED_HOSTS=localhost,127.0.0.1,your-domain.com
CORS_ORIGINS=http://localhost:3000,https://your-frontend-domain.com

